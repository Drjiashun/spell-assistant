# Locally Linear Embedding
# LLE feature selection
# LLE feature selection for regression tasks
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import LocallyLinearEmbedding
from sklearn.preprocessing import StandardScaler
import warnings
np.random.seed(42)
num_samples = 500
spectrum_length = 100
X = np.random.randn(num_samples, spectrum_length)
y = np.random.uniform(0, 10, num_samples)
print(f"Input data shape (X): {X.shape}")
print(f"Target data shape (y): {y.shape}")
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)
print("X data standardized.")
def lle_reconstruction_importance(X, n_neighbors=10, n_components=2, reg=1e-3, method='standard'):
    """
    Calculates heuristic feature importance based on LLE reconstruction error increase
    when a feature is removed for regression tasks.
    """
    n_samples, n_features = X.shape
    importance_scores = np.zeros(n_features)
    print(f"Calculating LLE importance (Method: {method}, Neighbors: {n_neighbors}, Components: {n_components})...")
    try:
        lle_base = LocallyLinearEmbedding(
            n_neighbors=n_neighbors,
            n_components=n_components,
            reg=reg,
            method=method,
            n_jobs=-1 # Use all available CPU cores
        )
        lle_base.fit(X)
        base_error = lle_base.reconstruction_error_
        if np.isnan(base_error) or np.isinf(base_error):
             raise ValueError("Base LLE resulted in NaN/Inf error.")
        print(f"  Baseline LLE Reconstruction Error: {base_error:.4f}")
    except Exception as e:
        warnings.warn(f"Base LLE failed: {e}. Cannot calculate importances.", RuntimeWarning)
        return None # Indicate failure
    for j in range(n_features):
        X_subset = np.delete(X, j, axis=1)
        if X_subset.shape[1] < n_components: # Check if enough features remain
            importance_scores[j] = 0 # Cannot run LLE, assume low importance
            continue
        try:
            lle_subset = LocallyLinearEmbedding(
                n_neighbors=n_neighbors,
                n_components=n_components,
                reg=reg,
                method=method,
                n_jobs=-1
            )
            lle_subset.fit(X_subset)
            subset_error = lle_subset.reconstruction_error_
            if np.isnan(subset_error) or np.isinf(subset_error):
                 subset_error = base_error # If subset fails, assume no change in error
                 warnings.warn(f"LLE failed for subset without feature {j}. Using base error.", RuntimeWarning)
            importance_scores[j] = max(0, subset_error - base_error)
        except Exception as e:
            warnings.warn(f"LLE failed for subset without feature {j}: {e}. Assigning 0 importance.", RuntimeWarning)
            importance_scores[j] = 0 # Assign 0 importance if LLE fails
    return importance_scores

N_NEIGHBORS = 15 # Default is 5, often needs adjustment
N_COMPONENTS_LLE = 5
LLE_METHOD = 'modified' # 'modified' is often more robust than 'standard'
LLE_REG = 1e-3
importance_scores_lle = lle_reconstruction_importance(
    X_scaled,
    n_neighbors=N_NEIGHBORS,
    n_components=N_COMPONENTS_LLE,
    method=LLE_METHOD,
    reg=LLE_REG
)

if importance_scores_lle is not None:
    IMPORTANCE_THRESHOLD_PERCENTILE = 90 # Select top 10% most important features
    if len(importance_scores_lle) > 0:
         threshold_value = np.percentile(importance_scores_lle, IMPORTANCE_THRESHOLD_PERCENTILE)
    else:
         threshold_value = 0
    selected_features_lle = np.where(importance_scores_lle > threshold_value)[0]
    if len(selected_features_lle) == 0 and len(importance_scores_lle) > 0:
         threshold_value = np.percentile(importance_scores_lle, 100 - (5/spectrum_length*100) ) # Select top 5 features maybe
         selected_features_lle = np.where(importance_scores_lle >= threshold_value)[0]
    print("\n--- LLE Heuristic Selection Results ---")
    print(f"Importance Threshold: > {IMPORTANCE_THRESHOLD_PERCENTILE}th percentile ({threshold_value:.4e})")
    print(f"Number of selected features: {len(selected_features_lle)}")
    print(f"Selected feature indices (LLE): {selected_features_lle}")
    plt.figure(figsize=(12, 6))
    plt.bar(np.arange(spectrum_length), importance_scores_lle, color='purple', label='LLE Importance Score')
    plt.axhline(threshold_value, color='k', linestyle='--', label=f'Threshold ({threshold_value:.2e})')
    if len(selected_features_lle) > 0:
        selected_mask = np.zeros_like(importance_scores_lle)
        selected_mask[selected_features_lle] = importance_scores_lle[selected_features_lle]
        plt.stem(np.arange(spectrum_length), selected_mask, linefmt='g-', markerfmt='go', basefmt=' ',
                 label=f'Selected (> {IMPORTANCE_THRESHOLD_PERCENTILE}th %ile)')
    plt.xlabel('Feature Index'); plt.ylabel('Importance (Increase in Recon. Error)')
    plt.title(f'LLE Heuristic Variable Importance')
    plt.legend(); plt.grid(True, axis='y', linestyle=':')
    plt.show()
