# LMC Model Transfer
# Linear Model Correction Model Transfer
# Linear Model Correction
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.linear_model import LinearRegression # For coefficient correction
from sklearn.metrics import mean_squared_error
n_wavelengths = 50       # Number of spectral points
n_samples_master = 70  # Number of calibration samples for Master
n_samples_slave = 60   # Number of calibration samples for Slave (independent set)
n_samples_new = 25     # Number of new samples measured only on the Slave device
n_components_master = 10 # Example value for Master PLS model
n_components_slave = 10  # Example value for Slave PLS model (Needs its own optimization)
print(f"Number of wavelengths: {n_wavelengths}")
print(f"Master calibration samples: {n_samples_master}")
print(f"Slave calibration samples: {n_samples_slave}")
print(f"New samples on slave: {n_samples_new}")
print(f"PLS Components (Master): {n_components_master}")
print(f"PLS Components (Slave): {n_components_slave}")
X_master_cal = np.random.rand(n_samples_master, n_wavelengths)
Y_master_cal = np.random.rand(n_samples_master, 1)
X_slave_cal = np.random.rand(n_samples_slave, n_wavelengths)
Y_slave_cal =np.random.rand(n_samples_slave, 1)
X_slave_new = np.random.rand(n_samples_new, n_wavelengths)
Y_new_hypothetical = np.random.rand(n_samples_new, 1)
print(f"\nMaster cal spectra shape (X_master_cal): {X_master_cal.shape}")
print(f"Master cal Y shape (Y_master_cal): {Y_master_cal.shape}")
print(f"Slave cal spectra shape (X_slave_cal): {X_slave_cal.shape}")
print(f"Slave cal Y shape (Y_slave_cal): {Y_slave_cal.shape}")
print(f"New slave spectra shape (X_slave_new): {X_slave_new.shape}")
print(f"Hypothetical new Y shape (Y_new_hypothetical): {Y_new_hypothetical.shape}")
print(f"\nTraining Master calibration model (PLS, {n_components_master} components)...")
if Y_master_cal.ndim == 1: Y_master_cal = Y_master_cal.reshape(-1, 1)
model_master = PLSRegression(n_components=n_components_master, scale=False)
model_master.fit(X_master_cal, Y_master_cal)
coeffs_master = model_master.coef_
print("Master PLS model trained.")
print(f"Master coefficients shape: {coeffs_master.shape}")
print(f"\nTraining Slave calibration model (PLS, {n_components_slave} components)...")
if Y_slave_cal.ndim == 1: Y_slave_cal = Y_slave_cal.reshape(-1, 1)
X_slave_cal_mean = np.mean(X_slave_cal, axis=0)
Y_slave_cal_mean = np.mean(Y_slave_cal, axis=0) # axis=0 gives mean of the column(s)
print(f"Manually calculated Slave X mean shape: {X_slave_cal_mean.shape}")
print(f"Manually calculated Slave Y mean shape: {Y_slave_cal_mean.shape}") # Should be (1,) or (n_targets,)
model_slave = PLSRegression(n_components=n_components_slave, scale=False)
model_slave.fit(X_slave_cal, Y_slave_cal)
coeffs_slave = model_slave.coef_
print("Slave PLS model trained (to get coefficients).")
print(f"Slave coefficients shape: {coeffs_slave.shape}")
print("\nTraining Coefficient Correction Model (Linear Regression)...")
if coeffs_master.shape[0] == 1 and coeffs_slave.shape[0] == 1:
    input_coeffs = coeffs_master.T
    target_coeffs = coeffs_slave.T
    model_coeff_correction = LinearRegression()
    model_coeff_correction.fit(input_coeffs, target_coeffs)
    print("Coefficient correction model trained.")
    print(f"Coefficient Correction Model - Scale: {model_coeff_correction.coef_[0,0]:.4f}, Offset: {model_coeff_correction.intercept_[0]:.4f}")
else:
    print("Error: Coefficient correction currently implemented for single target (Y) only.")
    exit()
print("\nTransforming Master coefficients...")
coeffs_master_transformed = model_coeff_correction.predict(input_coeffs)
coeffs_master_transformed = coeffs_master_transformed.T
print(f"Transformed master coefficients shape: {coeffs_master_transformed.shape}")
print("\nPredicting new slave samples using transformed coefficients...")
x_slave_mean_manual = X_slave_cal_mean
y_slave_mean_manual = Y_slave_cal_mean
X_slave_new_centered = X_slave_new - x_slave_mean_manual
Y_pred_corrected = X_slave_new_centered @ coeffs_master_transformed.T + y_slave_mean_manual
print(f"LMC Corrected predictions shape: {Y_pred_corrected.shape}")
Y_pred_original_master = model_master.predict(X_slave_new)
print("\n--- Prediction Results (Example) ---")
for i in range(min(5, n_samples_new)):
    print(f"Sample {i+1}:")
    print(f"  Hypothetical True Y: {Y_new_hypothetical[i, 0]:.2f}")
    print(f"  Predicted Y (Master PLS on Slave Data): {Y_pred_original_master[i, 0]:.2f}")
    print(f"  Predicted Y (LMC Corrected): {Y_pred_corrected[i, 0]:.2f}")
mse_original = mean_squared_error(Y_new_hypothetical, Y_pred_original_master)
mse_corrected = mean_squared_error(Y_new_hypothetical, Y_pred_corrected)
print("\n--- Prediction Performance (MSE vs Hypothetical Y) ---")
print(f"MSE using Original Master PLS Model on Slave Data: {mse_original:.4f}")
print(f"MSE using Linear Model Correction (LMC): {mse_corrected:.4f}")
plt.figure(figsize=(15, 10))
wavelength_indices = np.arange(n_wavelengths)
plt.subplot(2, 3, 1)
plt.plot(wavelength_indices, coeffs_master.flatten(), label='Master Coeffs', alpha=0.8)
plt.plot(wavelength_indices, coeffs_slave.flatten(), label='Slave Coeffs', alpha=0.8)
plt.plot(wavelength_indices, coeffs_master_transformed.flatten(), label='Transformed Master Coeffs', linestyle='--', linewidth=2)
plt.title('PLS Regression Coefficients')
plt.xlabel('Wavelength Index')
plt.ylabel('Coefficient Value')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)
plt.subplot(2, 3, 2)
plt.scatter(input_coeffs, target_coeffs, alpha=0.7, label='Actual Coeffs (Slave vs Master)')
plt.plot(input_coeffs, model_coeff_correction.predict(input_coeffs), color='red', linewidth=2, label='Correction Fit')
plt.title('Coefficient Correction Model')
plt.xlabel('Master Coefficient Value')
plt.ylabel('Slave Coefficient Value')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)
plt.subplot(2, 3, 3)
sample_indices = np.arange(n_samples_new)
plt.scatter(sample_indices, Y_new_hypothetical, label='Hypothetical True Y', marker='o', alpha=0.7)
plt.scatter(sample_indices, Y_pred_original_master, label='Pred. (Master on Slave)', marker='x', alpha=0.7)
plt.scatter(sample_indices, Y_pred_corrected, label='Pred. (LMC Corrected)', marker='+', alpha=0.9, s=80)
plt.title('Prediction Comparison for New Samples')
plt.xlabel('New Sample Index')
plt.ylabel('Predicted/Hypothetical Y Value')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)
plt.subplot(2, 3, 4)
all_preds = np.concatenate([Y_new_hypothetical.flatten(), Y_pred_original_master.flatten(), Y_pred_corrected.flatten()])
min_val = all_preds.min() * 0.9 if all_preds.size > 0 else 0
max_val = all_preds.max() * 1.1 if all_preds.size > 0 else 1
plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal (y=x)')
plt.scatter(Y_new_hypothetical, Y_pred_original_master, label=f'Master on Slave (MSE={mse_original:.2f})', marker='x', alpha=0.7)
plt.scatter(Y_new_hypothetical, Y_pred_corrected, label=f'LMC Corrected (MSE={mse_corrected:.2f})', marker='+', alpha=0.9, s=80)
plt.title('Predicted vs. Hypothetical Y')
plt.xlabel('Hypothetical True Y')
plt.ylabel('Predicted Y')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)
plt.axis('equal')
plt.xlim(min_val, max_val)
plt.ylim(min_val, max_val)
plt.subplot(2, 3, 5)
plt.plot(wavelength_indices, X_master_cal[0,:], label='Example Master Cal Spectrum')
plt.plot(wavelength_indices, X_slave_cal[0,:], label='Example Slave Cal Spectrum', linestyle='--')
plt.title('Example Calibration Spectra')
plt.xlabel('Wavelength Index')
plt.ylabel('Random Intensity')
plt.legend()
plt.subplot(2, 3, 6)
plt.plot(wavelength_indices, X_slave_new[0,:], label='Example New Slave Spectrum')
plt.title('Example New Slave Spectrum')
plt.xlabel('Wavelength Index')
plt.ylabel('Random Intensity')
plt.legend()
plt.tight_layout()
plt.show()
print("\nCode execution finished.")